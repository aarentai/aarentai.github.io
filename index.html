<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>Haocheng Dai</title>
    <meta name="description" content="i am an applied scientist at amazon.">
    <meta name="keywords" content="Haocheng Dai, haocheng">
    <meta name="author" content="Haocheng Dai">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,500,600,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Newsreader:ital,wght@0,400;0,500;0,700;1,400&display=swap" rel="stylesheet">
    <link href="style.css" rel="stylesheet" type="text/css">
    <link href="pygments.css" rel="stylesheet" type="text/css">
</head>

<body>
    <div class="container">
        <div class="row top">
            <div class="col-lg-offset-2 col-lg-8 col-md-offset-1 col-md-10 col-sm-12">
                <div class="row">
                    <div class="col-md-10">
                        <h1>Haocheng Dai</h1>
                        <br>
                        <h3><a href="CV.pdf">vitae</a> / <a href="https://www.linkedin.com/in/haocheng-dai-982740113/">linkedin</a> / <a href="https://github.com/aarentai">github</a> / <a href="https://www.youtube.com/channel/UCVT8QysnCZqdisAyo0CI0-g?view_as=subscriber">youtube</a> / <a href="https://www.flickr.com/photos/189454914@N06/">flickr</a> / <a href="https://www.instagram.com/aarent/?hl=en">instagram</a></h3>
                    </div>
                </div>

                <div class="row" style="padding-top: 20px">
                    <div class="col-md-12">
                        <p class="justified-text">i am an applied scientist at <a href="https://www.amazon.science/">amazon science</a> working on <a href="https://www.aboutamazon.com/news/retail/how-to-use-amazon-rufus">rufus</a>, the next generation llm-based conversational shopping assistant. 
                        <br>
                        <br>
                        i earned my <a href="utah_diploma.pdf">doctoral degree</a> in computer science from the <a href="http://www.utah.edu">university of utah</a> â€” the birthplace of <a href="https://spectrum.ieee.org/history-of-computer-graphics-industry">computer graphics</a> and the embryo of the current worldwide internet (<a href="https://attheu.utah.edu/facultystaff/birth-of-the-internet/">arpanet</a>). i was fortunate to be mentored by dr. <a href="https://scholar.google.com/citations?user=GyqdQTEAAAAJ&hl=en">sarang joshi</a> with affiliations to the <a href="http://www.sci.utah.edu">scientific computing and imaging institute</a> and <a href="http://www.cs.utah.edu">kahlert school of computing</a>. i also work closely with researchers from <a href="http://www.fsu.edu">fsu</a>, <a href="http://www.ucla.edu">ucla</a>, <a href="http://www.virginia.edu">uva</a>, and <a href="http://www.yale.edu">yale</a>. 
                        <br>
                        <br>
                        before i joined the u, i received my bachelor degree in computer science from <a href="https://en.tongji.edu.cn/">tongji university</a> and have studied at <a href="https://www.technion.ac.il/en/home-2/">israel institute of technology</a> and <a href="https://www.math.univ-toulouse.fr/?lang=en">institut de mathÃ©matiques de toulouse</a> as an exchange student, focusing on image analysis and riemannian geometry, respectively. 
                        <br>
                        <br>
                        currently, i am passionate about developing specialized and trustworthy machine learning tools. my research extends to, but is not limited to: ğŸ“„large language models and retrieval-augmented generation; ğŸ‘¨â€âš–ï¸trustworthy machine learning (fairness and robustness); ğŸ‘ï¸vision language and diffusion models; ğŸ“geometric deep learning and shape modeling; and ğŸ”­physics-informed machine learning.
                        </p>                        
                        </div>
                </div><br>
                <br>

                <h4>publications & preprints</h4>
                <br>
                <div class="talk">
                    <h5><a
                            href="https://arxiv.org/abs/2405.14030">Refining Skewed Perceptions in Vision-Language Models through Visual Representations.</a></h5>
                    <ul>
                        <li><span class="highlighted">Haocheng Dai</span>, Sarang Joshi.</li>
                        <li class="venue"><i>Preprint, 2024</i></li>
                        ğŸ‘¨â€âš–ï¸ğŸ‘ï¸ / <a href="https://arxiv.org/pdf/2405.14030">Paper</a> / <a href="https://github.com/aarentai/Spurious-VLM">Code</a> / <a href="./slides/cvpr.pdf">Slides</a> / <a href="./citations/nips2024.txt">Citation</a>
                    </ul>
                </div>
                <br>
                <p class="aligncenter">
                    <img src="./figures/nips2024.png" alt="pmb" width="95%" />
                </p>
                <br><br>

                <div class="talk">
                    <h5><a href="https://arxiv.org/abs/2501.00961">The Silent Majority: Demystifying Memorization Effect in the Presence of Spurious Correlations.</a></h5>
                    <ul>
                        <li>Chenyu You*, <span class="highlighted">Haocheng Dai*</span>, Yifei Min*, Jasjeet Sekhon, Sarang Joshi, James Duncan. (*equal contribution)</li>
                        <li class="venue"><i>Preprint, 2024</i></li>
                        ğŸ‘¨â€âš–ï¸ğŸ‘ï¸ / <a href="https://arxiv.org/pdf/2501.00961">Paper</a> / <a href="https://github.com/aarentai/Silent-Majority">Code</a> / <a href="./slides/nc.pdf">Slides</a> / <a href="./citations/nc.txt">Citation</a>
                    </ul>
                </div>
                <br>
                <p style="text-align: center;">
                    <img src="./figures/nc.png" alt="pmb" width="80%" />
                </p>
                <br><br>

                <div class="talk">
                    <h5><a
                            href="https://appliedradiationoncology.com/articles/high-fidelity-ct-on-rails-based-characterization-of-delivered-dose-variation-in-conformal-head-and-neck-treatments">High-Fidelity CT on Rails-Based Characterization of Delivered Dose Variation in Conformal Head and Neck Treatments.</a></h5>
                    <ul>
                        <li><span class="highlighted">Haocheng Dai</span>, Vikren Sarkar, Christian Dial, Markus Foote, Ying Hitchcock, Sarang Joshi, Bill Salter.</li>
                        <li class="venue"><i>Applied Radiation Oncology (ARO), 2023</i></li>
                        ğŸ‘¨â€âš–ï¸ğŸ§‘â€âš•ï¸ / <a href="https://cdn.agilitycms.com/applied-radiation-oncology/PDFs/issues/ARO_12-23_Dai.pdf">Paper</a> / <a href="https://github.com/aarentai/Radiation-Oncology">Code</a> / <a href="./slides/aro2023.pdf">Slides</a> / <a href="./citations/aro2023.txt">Citation</a>
                    </ul>
                </div>
                <br>
                <p class="aligncenter">
                    <img src="./figures/aro2023.png" alt="pmb" width="95%" />
                </p>
                <br><br>
                
                <div class="talk">
                    <h5><a href="https://drive.google.com/file/d/16-bv_mvt8WwnHbXCkW_kExM0g817Ki03/view?usp=sharing"> Detect AI-generated Images Uploaded for Risk Evidence Collection in CSSW.</a></h5>
                    <ul>
                        <li><span class="highlighted">Haocheng Dai</span>, Siwei Chen, Bei Xiao, Yangho Chen.</li>
                        <li class="venue"><i>Amazon Machine Learning Conference (AMLC), 2023</i></li>
                        ğŸ‘¨â€âš–ï¸ğŸ‘ï¸ / <a href="https://drive.google.com/file/d/16-bv_mvt8WwnHbXCkW_kExM0g817Ki03/view?usp=sharing">Paper</a> / <a href="./citations/amlc2023.txt">Citation</a>
                    </ul>
                </div>
                <br>
                <p class="aligncenter">
                    <img src="./figures/amlc2023.png" alt="ipmi" width="95%" />
                </p>
                <br><br>
                
                <div class="talk">
                    <h5><a href="https://openreview.net/forum?id=tSokLyjvW5">Neural Operator Learning for Ultrasound Tomography Inversion.</a></h5>
                    <ul>
                        <li><span class="highlighted">Haocheng Dai*</span>, Michael Penwarden*, Mike Kirby, Sarang Joshi. (*equal contribution)</li>
                        <li class="venue"><i>International Conference on Medical Imaging with Deep Learning (MIDL), 2023</i></li>
                        ğŸ§‘â€âš•ï¸ğŸ”­ / <a href="https://arxiv.org/abs/2304.03297">Paper</a> / <a href="https://github.com/aarentai/Ultrasound-Tfno-MIDL">Code</a> / <a href="./slides/midl2023.pdf">Slides</a> / <a href="./posters/midl2023.pdf">Poster</a> / <a href="./citations/midl2023.txt">Citation</a>
                    </ul>
                </div>
                <br>
                <p class="aligncenter">
                    <img src="./figures/midl2023.png" alt="midl" width="95%" />
                </p>
                <br><br>
                
                <div class="talk">
                    <h5><a href="https://link.springer.com/chapter/10.1007/978-3-031-34048-2_23">Modeling the Shape of the Brain Connectome via Deep Neural Networks.</a></h5>
                    <ul>
                        <li><span class="highlighted">Haocheng Dai</span>, Martin Bauer, Tom Fletcher, Sarang Joshi.</li>
                        <li class="venue"><i>International Conference on Information Processing in Medical Imaging (IPMI), 2023</i></li>
                        <li class="venue">Oral Presentation</li>
                        ğŸ§‘â€âš•ï¸ğŸ“ğŸ”­ / <a href="https://arxiv.org/abs/2203.06122">Paper</a> / <a href="https://github.com/aarentai/Metric-Cnn-3D-IPMI">Code</a> / <a href="./slides/ipmi2023.pdf">Slides</a> / <a href="https://youtu.be/Dwn2Gp8HFJ8">YouTube</a> / <a href="./citations/ipmi2023.txt">Citation</a> / <a href="https://towardsdatascience.com/ml-neuroscience-march-2022-must-reads-4d5d32dc80ed">Media Coverage</a>
                    </ul>
                </div>
                <br>
                <p class="aligncenter">
                    <img src="./figures/ipmi2023.png" alt="ipmi" width="95%" />
                </p>
                <br><br>
                
                <div class="talk">
                    <h5><a href="https://drive.google.com/file/d/1EQsFFwbGwwq9cH_u4mN77yxQB0xgDdo6/view?usp=sharing">
                            Understanding Visual Documents from Customer Self-Service Workflow using Multimodal Transformer.</a></h5>
                    <ul>
                        <li><span class="highlighted">Haocheng Dai</span>, Jia-Kai Chou, Siwei Chen, Bei Xiao, Yangho Chen.</li>
                        <li class="venue"><i>Amazon Machine Learning Conference (AMLC), 2022</i></li>
                        ğŸ‘ï¸ / <a href="https://drive.google.com/file/d/1EQsFFwbGwwq9cH_u4mN77yxQB0xgDdo6/view?usp=sharing">Paper</a> / <a href="./citations/amlc2022.txt">Citation</a>
                    </ul>
                </div>
                <br>
                <p class="aligncenter">
                    <img src="./figures/amlc2022.png" alt="ipmi" width="95%" />
                </p>
                <br><br>
                
                <div class="talk">
                    <h5><a href="https://www.melba-journal.org/papers/2022:016.html">Integrated Construction of Multimodal Atlases with Structural Connectomes in the Space of Riemannian Metrics.</a></h5>
                    <ul>
                        <li>Kris Campbell, <span class="highlighted">Haocheng Dai</span>, Zhe Su, Martin Bauer, Tom Fletcher, Sarang Joshi.</li>
                        <li class="venue"><i>Machine Learning for Biomedical Imaging (MELBA), 2022</i></li>
                        ğŸ§‘â€âš•ï¸ğŸ“ / <a href="https://arxiv.org/abs/2109.09808">Paper</a> / <a href="https://github.com/aarentai/Atlas-Building-3D">Code</a> / <a href="./citations/melba2022.txt">Citation</a>
                    </ul>
                    <br>
                </div>
                <p class="aligncenter">
                    <img src="./figures/melba2022.png" alt="melba" width="95%" />
                </p>
                <br><br>
                
                <div class="talk">
                    <h5><a href="https://link.springer.com/chapter/10.1007/978-3-030-78191-0_23">Structural Connectome Atlas Construction in the Space of Riemannian Metrics.</a></h5>
                    <ul>
                        <li>Kris Campbell, <span class="highlighted">Haocheng Dai</span>, Zhe Su, Martin Bauer, Tom Fletcher, Sarang Joshi.</li>
                        <li class="venue"><i>International Conference on Information Processing in Medical Imaging (IPMI), 2021</i></li>
                        <li class="venue"><a href="https://www.ipmi2023.org/en/ERBSMANN-PRIZES.html">FranÃ§ois Erbsmann Prize (Best Paper Award)</a></li>
                        ğŸ§‘â€âš•ï¸ğŸ“ / <a href="https://arxiv.org/abs/2103.05730">Paper</a> / <a href="https://github.com/aarentai/Atlas-Building-2D">Code</a> / <a href="./slides/ipmi2021.pdf">Slides</a> / <a href="./posters/ipmi2021.pdf">Poster</a> / <a href="./citations/ipmi2021.txt">Citation</a>
                    </ul>
                </div>
                <p class="aligncenter">
                    <img src="./figures/ipmi2021.png" alt="ipmi" width="95%" />
                </p>
                <br>
                <br>

                <h4>services</h4>
                <br>
                <p class="justified-text">
                    i have served as a reviewer for several journals and conferences, including <a href="https://2024.acmmm.org/">acm mm</a>, <a href="https://virtual.aistats.org/">aistats</a>, <a href="https://dl.acm.org/journal/tist">acm tist</a>, <a href="https://cvpr.thecvf.com/">cvpr</a>, <a href="https://www.appliedradiationoncology.com/">aro</a>, <a href="https://iclr.cc/">iclr</a>, <a href="https://icml.cc/">icml</a>, <a href="https://www.sciencedirect.com/journal/medical-image-analysis">media</a>, <a href="https://www.melba-journal.org/">melba</a>, <a href="https://conferences.miccai.org/2024/en/">miccai</a>, <a href="https://www.midl.io/">midl</a>, <a href="https://neurips.cc/">neurips</a>, <a href="https://www.nature.com/srep/">scientific reports</a>, <a href="https://ai4diffeqtnsinsci.github.io/program_committee">ai for differential equations in science@iclr</a>, and <a href="https://sites.google.com/view/wicveccv2024/home">wicv@eccv</a>.
                </p>
                <br>
                <br>
                
                <h4>miscellaneous</h4>
                <br>
                <p class="justified-text">
                    i made a handful of notes for better understanding in <a href="./notes/NoteonLanguageModels.pdf">language models</a>, <a href="./notes/NoteonMachineLearning.pdf">machine learning</a>, <a href="./notes/NoteonMathematicsofImaging.pdf">mathematics of imaging</a>, <a href="./notes/NoteonMetricEstimation.pdf">metric estimation</a>, <a href="./notes/NoteonRegistration.pdf">image registration</a>, and <a href="./notes/NoteonConjugateGradientMethod.pdf">solving large systems of linear equations</a>.<br>
                    <br>
                    my erdÅ‘s number = 4:<br>
                    haocheng dai -> sarang joshi -> ulf grenander -> oved shisha -> paul erdÅ‘s; <br>
                    haocheng dai -> mike kirby -> frank stenger -> ambikeshwar sharma -> paul erdÅ‘s. <br>
                    <br>
                    i am an amateur photographer, vlogger and also a loyal reader of ğŸ“° newspapers, you can
                    find the highlight front pages of <span class="highlighted">the new york times</span> i collect by the years of <a href="./NYTimes/NYT2012highlight.pdf">2012</a>, <a href="./NYTimes/NYT2013highlight.pdf">2013</a>, <a href="./NYTimes/NYT2014highlight.pdf">2014</a>, <a href="./NYTimes/NYT2015highlight.pdf">2015</a>, <a href="./NYTimes/NYT2016highlight.pdf">2016</a>, <a href="./NYTimes/NYT2017highlight.pdf">2017</a>, <a href="./NYTimes/NYT2018highlight.pdf">2018</a>, <a href="./NYTimes/NYT2019highlight.pdf">2019</a>, <a href="./NYTimes/NYT2020highlight.pdf">2020</a>, <a href="./NYTimes/NYT2021highlight.pdf">2021</a>, <a href="./NYTimes/NYT2022highlight.pdf">2022</a>, <a href="./NYTimes/NYT2023highlight.pdf">2023</a>, and <a href="./NYTimes/NYT2024highlight.pdf">2024</a>; the highlight front pages of <span class="highlighted">the washington post</span> I collect <a href="./WaPo/before2015.pdf">before 2015</a>, <a href="./WaPo/2016-2020.pdf">2016 - 2020</a>, and <a href="./WaPo/2021-2024.pdf">2021 - 2024</a>.
                </p>
                <br>
                <br>
                

                <h4>footprints</h4>
                <br>
                <p class="aligncenter">
                    <img src="./figures/MapChart_Map.png" alt="ipmi" width="95%" />
                </p>
                <br>
                <br>

            </div>
        </div>
    </div>

    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
        ga('create', 'UA-82486201-1', 'auto');
        ga('send', 'pageview');
    </script>
</body>

</html>